{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Check devices..\n",
      "Current device:  cuda\n",
      "Our selected device:  0\n",
      "1  GPUs is available\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "\n",
    "print(\"==> Check devices..\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Current device: \",device)\n",
    "\n",
    "#Also can print your current GPU id, and the number of GPUs you can use.\n",
    "print(\"Our selected device: \", torch.cuda.current_device())\n",
    "print(torch.cuda.device_count(), \" GPUs is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The transform function for train data\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "#The transform function for test data\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "#Use API to load CIFAR10 train dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='D:\\\\dataset\\\\cifar10', train=True, download=False, transform=transform_train)\n",
    "\n",
    "#Use API to load CIFAR10 test dataset\n",
    "testset = torchvision.datasets.CIFAR10(root='D:\\\\dataset\\\\cifar10', train=False, download=False, transform=transform_test)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    #define the layers\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    #concatenate these layers\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(2):\n",
    "    models.append(Net())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimization algorithm\n",
    "optimizer = []\n",
    "for i in range(2):\n",
    "    optimizer.append(optim.SGD(models[i].parameters(), lr=0.001, momentum=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testInd(ind):\n",
    "    ind.eval()\n",
    "    ind = ind.to(device)\n",
    "    correct = 0\n",
    "    running_loss = 0.0\n",
    "    iter_count = 0\n",
    "    class_correct = [0 for i in range(10)]\n",
    "    class_total = [0 for i in range(10)]\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device) \n",
    "            labels = labels.to(device)\n",
    "            outputs = ind(images)\n",
    "            _, pred = outputs.max(1)\n",
    "            correct += pred.eq(labels).sum().item()\n",
    "            c_eachlabel = pred.eq(labels).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            iter_count += 1\n",
    "            running_loss += loss.item()\n",
    "            for i in range(len(labels)):# 32 is batch size\n",
    "                cur_label = labels[i]\n",
    "                class_correct[cur_label] += c_eachlabel[i].item()\n",
    "                class_total[cur_label] += 1\n",
    "    ind = ind.to('cpu')\n",
    "    return 100 * correct/len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.01, 9.76]\n"
     ]
    }
   ],
   "source": [
    "fitness = []\n",
    "with torch.no_grad():\n",
    "    for ind in models:\n",
    "        fitness.append(testInd(ind))\n",
    "    print(fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossover\n",
    "children = []\n",
    "child1 = Net()\n",
    "child2 = Net()\n",
    "mask = np.array([0,1,0,1,0])\n",
    "                \n",
    "child1.conv1.weight = models[0].conv1.weight if mask[0] else models[1].conv1.weight\n",
    "child1.conv1.bias   = models[0].conv1.bias   if mask[0] else models[1].conv1.bias\n",
    "child2.conv1.weight = models[1].conv1.weight if mask[0] else models[0].conv1.weight\n",
    "child2.conv1.bias   = models[1].conv1.bias   if mask[0] else models[0].conv1.bias\n",
    "\n",
    "child1.conv2.weight = models[0].conv2.weight if mask[1] else models[1].conv2.weight\n",
    "child1.conv2.bias   = models[0].conv2.bias   if mask[1] else models[1].conv2.bias\n",
    "child2.conv2.weight = models[1].conv2.weight if mask[1] else models[0].conv2.weight\n",
    "child2.conv2.bias   = models[1].conv2.bias   if mask[1] else models[0].conv2.bias\n",
    "\n",
    "child1.fc1.weight = models[0].fc1.weight if mask[2] else models[1].fc1.weight\n",
    "child1.fc1.bias   = models[0].fc1.bias   if mask[2] else models[1].fc1.bias\n",
    "child2.fc1.weight = models[1].fc1.weight if mask[2] else models[0].fc1.weight\n",
    "child2.fc1.bias   = models[1].fc1.bias   if mask[2] else models[0].fc1.bias\n",
    "\n",
    "child1.fc2.weight = models[0].fc2.weight if mask[3] else models[1].fc2.weight\n",
    "child1.fc2.bias   = models[0].fc2.bias   if mask[3] else models[1].fc2.bias\n",
    "child2.fc2.weight = models[1].fc2.weight if mask[3] else models[0].fc2.weight\n",
    "child2.fc2.bias   = models[1].fc2.bias   if mask[3] else models[0].fc2.bias\n",
    "\n",
    "child1.fc3.weight = models[0].fc3.weight if mask[4] else models[1].fc3.weight\n",
    "child1.fc3.bias   = models[0].fc3.bias   if mask[4] else models[1].fc3.bias\n",
    "child2.fc3.weight = models[1].fc3.weight if mask[4] else models[0].fc3.weight\n",
    "child2.fc3.bias   = models[1].fc3.bias   if mask[4] else models[0].fc3.bias\n",
    "\n",
    "children.append(child1)\n",
    "children.append(child2)\n",
    "if True:\n",
    "    del models\n",
    "    torch.cuda.empty_cache()\n",
    "    models = children\n",
    "    optimizer = []\n",
    "    for i in range(2):\n",
    "        optimizer.append(optim.SGD(models[i].parameters(), lr=0.001, momentum=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.88, 9.99]\n"
     ]
    }
   ],
   "source": [
    "## Before Mutation\n",
    "with torch.no_grad():\n",
    "    # update fitness list\n",
    "    fitness = []\n",
    "    for ind in models:\n",
    "        fitness.append(testInd(ind))\n",
    "    print(fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,   200] loss: 2.300\n",
      "[0,   400] loss: 2.275\n",
      "[0,   600] loss: 2.212\n",
      "[0,   800] loss: 2.101\n",
      "[0,  1000] loss: 1.995\n",
      "[0,  1200] loss: 1.925\n",
      "[0,  1400] loss: 1.880\n",
      "Model 0 training accuracy: 22.6620\n",
      "[1,   200] loss: 2.296\n",
      "[1,   400] loss: 2.243\n",
      "[1,   600] loss: 2.123\n",
      "[1,   800] loss: 2.034\n",
      "[1,  1000] loss: 1.987\n",
      "[1,  1200] loss: 1.918\n",
      "[1,  1400] loss: 1.863\n",
      "Model 1 training accuracy: 23.3000\n"
     ]
    }
   ],
   "source": [
    "# Mutation\n",
    "for idx in range(len(models)):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    models[idx].to(device)\n",
    "    models[idx].train()\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "\n",
    "        inputs = inputs.to(device) \n",
    "        labels = labels.to(device) \n",
    "\n",
    "        optimizer[idx].zero_grad()\n",
    "\n",
    "        outputs = models[idx](inputs)\n",
    "        _, pred = outputs.max(1)\n",
    "        correct += pred.eq(labels).sum().item()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer[idx].step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print('[{}, {:5d}] loss: {:.3f}'.format(idx, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "    print('Model {} training accuracy: {:.4f}'.format(idx, 100.*correct/len(trainset)))\n",
    "    models[idx].to('cpu')\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33.18, 35.52]\n"
     ]
    }
   ],
   "source": [
    "## After mutation\n",
    "with torch.no_grad():\n",
    "    # update fitness list\n",
    "    fitness = []\n",
    "    for ind in models:\n",
    "        fitness.append(testInd(ind))\n",
    "    print(fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
